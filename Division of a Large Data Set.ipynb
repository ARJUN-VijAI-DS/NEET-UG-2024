{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6f8faf2",
   "metadata": {},
   "source": [
    "## Dividing a large dataset based on the unique values in one of its columns can be useful for various purposes, such as creating subsets of data for individual analysis, parallel processing, or categorizing data. Hereâ€™s a step-by-step guide on how to do this using Python and Pandas:\n",
    "\n",
    "### Steps to Divide a Dataset Based on Unique Column Values\n",
    "- Identify the column with unique values: Determine which column's unique values will be used to split the dataset.\n",
    "- Extract unique values: Get a list of all unique values in that column.\n",
    "- Create subsets: For each unique value, create a subset of the dataset where the column's value matches the unique value.\n",
    "\n",
    "### Example\n",
    "- Let's assume we have a dataset df and we want to split it based on the unique values in the column category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fdd9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'category': ['A', 'B', 'A', 'C', 'B', 'A', 'C'],\n",
    "    'value': [10, 20, 10, 30, 20, 40, 30]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Identify the column with unique values\n",
    "column_name = 'category'\n",
    "\n",
    "# Step 2: Extract unique values\n",
    "unique_values = df[column_name].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4251e5",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "- Identify the column with unique values: In this example, the column category is used.\n",
    "- Extract unique values: unique_values contains all unique values in the category column (['A', 'B', 'C']).\n",
    "- Create subsets: A dictionary subsets is created where each key is a unique value from the category column, and the value is the subset of the DataFrame corresponding to that unique value.\n",
    "\n",
    "## Accessing the Subsets\n",
    "- After creating the subsets, you can access them using the unique values as keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afcb63bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  category  value\n",
      "0        A     10\n",
      "2        A     10\n",
      "5        A     40\n",
      "  category  value\n",
      "1        B     20\n",
      "4        B     20\n",
      "  category  value\n",
      "3        C     30\n",
      "6        C     30\n"
     ]
    }
   ],
   "source": [
    "# Access the subset for category 'A'\n",
    "subset_A = subsets['A']\n",
    "print(subset_A)\n",
    "\n",
    "# Access the subset for category 'B'\n",
    "subset_B = subsets['B']\n",
    "print(subset_B)\n",
    "\n",
    "# Access the subset for category 'C'\n",
    "subset_C = subsets['C']\n",
    "print(subset_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab3f9f3",
   "metadata": {},
   "source": [
    "## Practical Considerations\n",
    "- **Memory Usage:** Be cautious with memory usage if the dataset is very large. Creating multiple subsets can significantly increase memory usage.\n",
    "- **Parallel Processing:** If you plan to process each subset separately, consider using parallel processing techniques to improve performance.\n",
    "- **Data Integrity:** Ensure that the column used for splitting has been preprocessed and cleaned to avoid issues with inconsistent or missing values.\n",
    "- By following these steps, you can effectively divide a large dataset based on the unique values in a specific column, allowing for more focused and manageable analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7efe338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset for category 'A':\n",
      "  category  value\n",
      "0        A     10\n",
      "2        A     10\n",
      "5        A     40\n",
      "\n",
      "Subset for category 'B':\n",
      "  category  value\n",
      "1        B     20\n",
      "4        B     20\n",
      "\n",
      "Subset for category 'C':\n",
      "  category  value\n",
      "3        C     30\n",
      "6        C     30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'category': ['A', 'B', 'A', 'C', 'B', 'A', 'C'],\n",
    "    'value': [10, 20, 10, 30, 20, 40, 30]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Identify the column with unique values\n",
    "column_name = 'category'\n",
    "\n",
    "# Step 2: Extract unique values\n",
    "unique_values = df[column_name].unique()\n",
    "\n",
    "# Step 3: Create subsets\n",
    "subsets = {}\n",
    "for value in unique_values:\n",
    "    subsets[value] = df[df[column_name] == value]\n",
    "\n",
    "# Now `subsets` is a dictionary where each key is a unique value from the column,\n",
    "# and the value is the corresponding subset of the DataFrame.\n",
    "\n",
    "# Access and print the subsets for each unique category\n",
    "for value in unique_values:\n",
    "    print(f\"Subset for category '{value}':\")\n",
    "    print(subsets[value])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09a065e",
   "metadata": {},
   "source": [
    "## In the code above:\n",
    "\n",
    "- The DataFrame df is created correctly.\n",
    "- The column_name is identified as category.\n",
    "- Unique values are extracted using df[column_name].unique().\n",
    "- Subsets are created and stored in the subsets dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b0bab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset for category 'A':\n",
      "  category  value\n",
      "0        A     10\n",
      "2        A     10\n",
      "5        A     40\n",
      "Subset for category 'B':\n",
      "  category  value\n",
      "1        B     20\n",
      "4        B     20\n",
      "Subset for category 'C':\n",
      "  category  value\n",
      "3        C     30\n",
      "6        C     30\n"
     ]
    }
   ],
   "source": [
    "# Optionally, print a specific subset if needed\n",
    "# Access the subset for category 'A'\n",
    "subset_A = subsets['A']\n",
    "print(\"Subset for category 'A':\")\n",
    "print(subset_A)\n",
    "\n",
    "# Access the subset for category 'B'\n",
    "subset_B = subsets['B']\n",
    "print(\"Subset for category 'B':\")\n",
    "print(subset_B)\n",
    "\n",
    "# Access the subset for category 'C'\n",
    "subset_C = subsets['C']\n",
    "print(\"Subset for category 'C':\")\n",
    "print(subset_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7f4d41",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "### If the code is not working as expected, consider checking the following:\n",
    "\n",
    "- Ensure the DataFrame df is correctly created and populated.\n",
    "- Verify the column name category is correct and exists in the DataFrame.\n",
    "- Check for any errors or exceptions in the code execution, and ensure all necessary libraries (e.g., pandas) are imported and installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f87860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset for category 'A' has been saved to subset_A.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the subset for category 'A' to a CSV file\n",
    "subset_A.to_csv('subset_A.csv', index=False)\n",
    "\n",
    "print(\"Subset for category 'A' has been saved to subset_A.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d62548",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "- Create the DataFrame: The sample DataFrame df is created.\n",
    "- Identify and extract unique values: The unique values in the column category are extracted.\n",
    "- Create subsets: Subsets are created and stored in the subsets dictionary.\n",
    "- Access and print subsets: Each subset is printed for verification.\n",
    "- Save subset to CSV: The subset for category 'A' is saved to a CSV file named subset_A.csv using the to_csv method. The index=False parameter is used to exclude the DataFrame index from the CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0af53e0",
   "metadata": {},
   "source": [
    "## Result\n",
    "- After running the code, you should have a CSV file named \"subset_A.csv\" in your working directory, containing the subset of the DataFrame where the category is 'A'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2171baac",
   "metadata": {},
   "source": [
    "### The .csv file will be stored in the current working directory of your script or notebook. The current working directory is the directory from which the script is run or where the Jupyter notebook is located.\n",
    "\n",
    "- To determine the current working directory in your script or notebook, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f143e765",
   "metadata": {},
   "outputs": [],
   "source": [
    "Subset_A = subset_A.to_csv('C:\\\\Users\\\\user\\\\Desktop\\\\NEET DATA_ Analysis\\\\subset_A.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c926353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file will be saved in: C:\\Users\\user\\__ Machine_Learning\\NEET UG 2024_Toy Data Set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(f\"The CSV file will be saved in: {current_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad20dae",
   "metadata": {},
   "source": [
    "## This will print the path to the directory where the CSV file will be saved.\n",
    "\n",
    "- If you want to save the CSV file to a specific directory, you can provide the full path to the to_csv method. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380356e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa74ea5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9f04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf75d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1f7587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the subset for category 'A' to a specific directory\n",
    "subset_A.to_csv('/path/to/your/directory/subset_A.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1935379",
   "metadata": {},
   "source": [
    "## Replace '/path/to/your/directory/' with the desired directory path where you want to save the file.\n",
    "\n",
    "- Example Code with Directory Check\n",
    "- Here is the updated code with the addition of checking and printing the current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a1b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'category': ['A', 'B', 'A', 'C', 'B', 'A', 'C'],\n",
    "    'value': [10, 20, 10, 30, 20, 40, 30]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Identify the column with unique values\n",
    "column_name = 'category'\n",
    "\n",
    "# Step 2: Extract unique values\n",
    "unique_values = df[column_name].unique()\n",
    "\n",
    "# Step 3: Create subsets\n",
    "subsets = {}\n",
    "for value in unique_values:\n",
    "    subsets[value] = df[df[column_name] == value]\n",
    "\n",
    "# Now `subsets` is a dictionary where each key is a unique value from the column,\n",
    "# and the value is the corresponding subset of the DataFrame.\n",
    "\n",
    "# Access and print the subsets for each unique category\n",
    "for value in unique_values:\n",
    "    print(f\"Subset for category '{value}':\")\n",
    "    print(subsets[value])\n",
    "    print()\n",
    "\n",
    "# Access the subset for category 'A'\n",
    "subset_A = subsets['A']\n",
    "print(\"Subset for category 'A':\")\n",
    "print(subset_A)\n",
    "\n",
    "# Get and print the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(f\"The CSV file will be saved in: {current_directory}\")\n",
    "\n",
    "# Save the subset for category 'A' to a CSV file\n",
    "subset_A.to_csv('subset_A.csv', index=False)\n",
    "\n",
    "print(\"Subset for category 'A' has been saved to subset_A.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fc643d",
   "metadata": {},
   "source": [
    "## Running this code will print the path to the current working directory, and you can confirm where the subset_A.csv file will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f786db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca67a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c1ce51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0ed937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"C:\\\\Users\\\\user\\\\Desktop\\\\NEET DATA_ Analysis\\\\NEET_2024_RESULTS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e613c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f4cf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrame to Excel\n",
    "### file_path = \"Segregated_data.xlsx\"\n",
    "### df.to_excel(\"C:\\\\Users\\\\user\\\\Desktop\\\\Machine Learning\\\\Boston_Housing.xlsx\", index=False)\n",
    "#### Syntax  --- df1.to_excel(\"C:\\\\Users\\\\user\\\\Desktop\\\\Machine Learning\\\\Boston_Housing.xlsx\")\n",
    "### print(\"Data has been exported to:\", file_path)\n",
    "df_final = pd.concat([df,df1,df2,df3],axis = 1)\n",
    "df_final\n",
    "df_final.to_excel(\"C:\\\\Users\\\\user\\\\Desktop\\\\Machine Learning\\\\Exam_copy.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2025815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb57db86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2a29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587f9589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
